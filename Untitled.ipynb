{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "686145cd-ec30-46ac-80e7-e8df912c1a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "from keras.layers import BatchNormalization\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "94248284-7095-4f9b-a029-5ccd707be5fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            filename   Gun   Knife   Pliers  \\\n",
      "0  P00392_jpg.rf.927a720cb4be08db58c89aa0bafe58ba...     1       1        0   \n",
      "1  P08714_jpg.rf.92ae9225b26d09c6efba68704c723e65...     0       0        1   \n",
      "2  P06862_jpg.rf.92b47b9cee6b711d9d26245b83cf3a27...     0       0        0   \n",
      "3  P00532_jpg.rf.92bc280cf669e4fd66d9f3b26a036c3c...     0       1        0   \n",
      "4  P08428_jpg.rf.92c57b5d947cda38d974ba0266aaf66d...     0       0        1   \n",
      "\n",
      "    Scissors   Wrench  \n",
      "0          0        0  \n",
      "1          0        0  \n",
      "2          1        0  \n",
      "3          0        0  \n",
      "4          0        0  \n",
      "Index(['filename', ' Gun', ' Knife', ' Pliers', ' Scissors', ' Wrench'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "image_directory = 'baggage/train'\n",
    "\n",
    "\n",
    "#Now let us read metadata to get our Y values (multiple lables)\n",
    "df = pd.read_csv('baggage/train_file/_classes.csv')    \n",
    "print(df.head())     # printing first five rows of the file\n",
    "print(df.columns)\n",
    "\n",
    "df = df.iloc[:2000]  #Loading only first 1000 datapoints for memory reasons \n",
    "#Need to read images using the tag from metadata.\n",
    "#Otherwise, if read directly from the folder then images may not correspond to \n",
    "#the metadata from the csv file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "42cb61a1-e332-4016-ae90-0532d611a28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 640"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e5d938e2-8869-41da-907d-90b594a811a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 files belonging to 0 classes.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No images found in directory baggage/train. Allowed formats: ('.bmp', '.gif', '.jpeg', '.jpg', '.png')",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_3592\\2585693245.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m dataset = tf.keras.preprocessing.image_dataset_from_directory(\n\u001b[0m\u001b[0;32m      2\u001b[0m      \u001b[1;34m\"baggage/train\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m      \u001b[0mshuffle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m      \u001b[0mimage_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mIMAGE_SIZE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIMAGE_SIZE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m      \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\image_dataset.py\u001b[0m in \u001b[0;36mimage_dataset_from_directory\u001b[1;34m(directory, labels, label_mode, class_names, color_mode, batch_size, image_size, shuffle, seed, validation_split, subset, interpolation, follow_links, crop_to_aspect_ratio, **kwargs)\u001b[0m\n\u001b[0;32m    292\u001b[0m         )\n\u001b[0;32m    293\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mimage_paths\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 294\u001b[1;33m             raise ValueError(\n\u001b[0m\u001b[0;32m    295\u001b[0m                 \u001b[1;34mf\"No images found in directory {directory}. \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    296\u001b[0m                 \u001b[1;34mf\"Allowed formats: {ALLOWLIST_FORMATS}\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: No images found in directory baggage/train. Allowed formats: ('.bmp', '.gif', '.jpeg', '.jpg', '.png')"
     ]
    }
   ],
   "source": [
    "dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "     \"baggage/train\", \n",
    "     shuffle = True,\n",
    "     image_size = (IMAGE_SIZE, IMAGE_SIZE),\n",
    "     batch_size = BATCH_SIZE\n",
    " )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7d497e08-91ae-469f-93c1-1634979acbc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 images belonging to 0 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Set the image size and batch size\n",
    "SIZE = 200\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Create an ImageDataGenerator instance\n",
    "datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
    "\n",
    "# Flow from directory using the ImageDataGenerator\n",
    "image_generator = datagen.flow_from_directory(\n",
    "    directory=image_directory,\n",
    "    target_size=(SIZE, SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=None,  # Set class_mode to None for uploading images without labels\n",
    "    shuffle=False  # Set shuffle to False to maintain the order of the images\n",
    ")\n",
    "\n",
    "# Upload images\n",
    "images = next(image_generator)\n",
    "\n",
    "\n",
    "#SIZE = 200\n",
    "#X_dataset = []  \n",
    "#for i in tqdm(range(df.shape[0])):\n",
    "#    img = image.load_img(image_directory +df['filename'][i], target_size=(SIZE,SIZE,3))\n",
    "#    img = image.img_to_array(img)\n",
    "#    img = img/255.\n",
    "#    X_dataset.append(img)\n",
    "#    \n",
    "#X = np.array(X_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b77196ec-8092-4270-a03e-cbb201315b4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            filename   Gun   Knife   Pliers  \\\n",
      "0  P00392_jpg.rf.927a720cb4be08db58c89aa0bafe58ba...     1       1        0   \n",
      "1  P08714_jpg.rf.92ae9225b26d09c6efba68704c723e65...     0       0        1   \n",
      "2  P06862_jpg.rf.92b47b9cee6b711d9d26245b83cf3a27...     0       0        0   \n",
      "3  P00532_jpg.rf.92bc280cf669e4fd66d9f3b26a036c3c...     0       1        0   \n",
      "4  P08428_jpg.rf.92c57b5d947cda38d974ba0266aaf66d...     0       0        1   \n",
      "\n",
      "    Scissors   Wrench  \n",
      "0          0        0  \n",
      "1          0        0  \n",
      "2          1        0  \n",
      "3          0        0  \n",
      "4          0        0  \n",
      "Index(['filename', ' Gun', ' Knife', ' Pliers', ' Scissors', ' Wrench'], dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2000 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'keras.preprocessing.image' has no attribute 'load_img'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_3592\\3593919281.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[0mX_dataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_img\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_directory\u001b[0m \u001b[1;33m+\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Id'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'.jpg'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSIZE\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mSIZE\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimg_to_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m255.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'keras.preprocessing.image' has no attribute 'load_img'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#Id and Genre are not labels to be trained. So drop them from the dataframe.\n",
    "#No need to convert to categorical as the dataset is already in the right format.\n",
    "#y = np.array(df.drop(['Id', 'Genre'], axis=1))\n",
    "y = np.array(df)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=20, test_size=0.3)\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters=16, kernel_size=(5, 5), activation=\"relu\", input_shape=(SIZE,SIZE,3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(filters=32, kernel_size=(5, 5), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(filters=64, kernel_size=(5, 5), activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(filters=64, kernel_size=(5, 5), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(25, activation='sigmoid'))\n",
    "\n",
    "#Do not use softmax for multilabel classification\n",
    "#Softmax is useful for mutually exclusive classes, either cat or dog but not both.\n",
    "#Also, softmax outputs all add to 1. So good for multi class problems where each\n",
    "#class is given a probability and all add to 1. Highest one wins. \n",
    "\n",
    "#Sigmoid outputs probability. Can be used for non-mutually exclusive problems.\n",
    "#like multi label, in this example.\n",
    "#But, also good for binary mutually exclusive (cat or not cat). \n",
    "\n",
    "model.summary()\n",
    "\n",
    "#Binary cross entropy of each label. So no really a binary classification problem but\n",
    "#Calculating binary cross entropy for each label. \n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test), batch_size=64)\n",
    "\n",
    "\n",
    "#plot the training and validation accuracy and loss at each epoch\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(loss) + 1)\n",
    "plt.plot(epochs, loss, 'y', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "plt.plot(epochs, acc, 'y', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#################################################\n",
    "#Validate on an image\n",
    "#img = image.load_img('movie_dataset_multilabel/images/tt4425064.jpg', target_size=(SIZE,SIZE,3))\n",
    "img = image.load_img('ddlj.jpg', target_size=(SIZE,SIZE,3))\n",
    "\n",
    "img = image.img_to_array(img)\n",
    "img = img/255.\n",
    "plt.imshow(img)\n",
    "img = np.expand_dims(img, axis=0)\n",
    "\n",
    "classes = np.array(df.columns[2:]) #Get array of all classes\n",
    "proba = model.predict(img)  #Get probabilities for each class\n",
    "sorted_categories = np.argsort(proba[0])[:-11:-1]  #Get class names for top 10 categories\n",
    "\n",
    "#Print classes and corresponding probabilities\n",
    "for i in range(10):\n",
    "    print(\"{}\".format(classes[sorted_categories[i]])+\" ({:.3})\".format(proba[0][sorted_categories[i]]))\n",
    "\n",
    "###################################################\n",
    "\n",
    "_, acc = model.evaluate(X_test, y_test)\n",
    "print(\"Accuracy = \", (acc * 100.0), \"%\")\n",
    "\n",
    "################################################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c487493-8255-428b-bc8f-c363c0f9e976",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
